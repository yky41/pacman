<div align="center">

ğŸ® Enhanced Pac-Man with Deep Reinforcement Learning
A custom Pac-Man environment where a DQN agent learns to master gameplay with dynamic, score-triggered abilities.

</div>

<p align="center">
<img src="https://img.shields.io/badge/Python-3.9+-blue.svg" alt="Python Version">
<img src="https://img.shields.io/badge/Framework-Pygame-green.svg" alt="Framework">
<img src="https://img.shields.io/badge/Library-PyTorch-orange.svg" alt="Library">
<img src="https://img.shields.io/badge/RL_Library-Stable_Baselines3-yellow.svg" alt="RL Library">
</p>

<br>
<p align="center">
<img src="Enhanced-Pacman-main/images/gameplay.png"
     alt="Game Screenshot"
     style="width:70%;">

</p>
<br>

ğŸš€ Project Overview
This project implements a custom Pac-Man environment from scratch using Pygame and integrates it with the Stable Baselines3 library to train a Deep Reinforcement Learning agent. The standard Pac-Man rules are enhanced with a "Super Mode", a powerful combination of skills that activates periodically, creating a dynamic environment where the agent's strategy must constantly adapt.

The goal is to demonstrate that through advanced feature engineering and careful reward shaping, a DQN agent can learn to master complex, non-stationary game mechanics.

âœ¨ Features
Feature

Description

ğŸ•¹ï¸ Classic Gameplay

Core mechanics including pellet collection and ghost evasion.

ğŸ—ºï¸ Two Maze Configurations

A SIMPLE 14x14 maze for rapid prototyping and a COMPLEX 28x31 maze for a harder challenge.

ğŸŒŸ "Super Mode"

Every 200 points, Pac-Man activates Boost, Invisibility, and Ghost Freeze simultaneously.

ğŸ¤– DQN Agent

Implemented using the robust Stable Baselines3 library.

gymnasium Custom Environment

The game is wrapped in a custom environment that follows the Gymnasium (formerly OpenAI Gym) interface.

ğŸ§  Advanced Feature Engineering

A 43-dimensional feature vector provides the agent with rich information, including skill timers and distinct ghost states.

ğŸ† Tuned Reward Function

A detailed reward shaping mechanism guides the agent to learn complex strategies and avoid common pitfalls.

ğŸ“Š TensorBoard Integration

For real-time monitoring of training progress and performance metrics.

ğŸ› ï¸ Getting Started
Requirements
Python 3.9+

Pygame

PyTorch

NumPy

Stable-Baselines3 (pip install stable-baselines3[extra])

Gymnasium (pip install gymnasium)

Pandas & Matplotlib (for result analysis)

Installation & Setup
Clone the repository:

git clone <your-repo-url>
cd Enhanced-Pacman-DQN

Install dependencies:

pip install pygame torch numpy "stable-baselines3[extra]" gymnasium pandas matplotlib

ğŸš€ Usage
All primary configurations (training, testing, maze type) are managed via flags at the top of the main.py file.

ğŸ§  Training a New Model
Open main.py and set the flags:

TRAINING_MODE = True
TESTING_MODE = False
MAZE_TYPE = "SIMPLE"  # or "COMPLEX"

Run the script from your terminal:

python main.py

The trained model will be saved in the outputs/models/ directory.

ğŸ§ª Testing a Trained Model
Ensure a trained model exists in outputs/models/.

Open main.py and set the flags:

TRAINING_MODE = False
TESTING_MODE = True
TEST_RENDER = True # Set to True to watch the agent play

Run the script:

python main.py

Test results, including a CSV file and summary plots, will be saved in a new timestamped folder inside outputs/test_results/.

ğŸ“ˆ Monitoring with TensorBoard
Launch TensorBoard from your terminal:

tensorboard --logdir=./outputs/logs/tensorboard

Open your web browser and navigate to http://localhost:6006.

âŒ¨ï¸ Controls
Key(s)

Action

1

Switch to HUMAN mode (manual control).

2

Switch to A_STAR mode (A* pathfinding AI).

3

Switch to DQN mode (RL agent).

â†‘â†“â†â†’

Move Pac-Man in Human mode.

M

Switch between SIMPLE and COMPLEX maze.

SPACE

Restart the game after a win or loss.

<details>
<summary>ğŸ“‚ Click to view Project Structure</summary>

Enhanced-Pacman-DQN/
â”œâ”€â”€ dqn/              # DQN implementation (environment, training, testing)
â”œâ”€â”€ entities/         # Game entities (Pacman, Ghost)
â”œâ”€â”€ rendering/        # Game rendering utilities
â”œâ”€â”€ utils/            # Helper functions (A* pathfinding, etc.)
â”œâ”€â”€ outputs/          # Saved models, training logs, and test results
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ images/           # Screenshots for README
â”œâ”€â”€ main.py           # Main game loop and entry point
â””â”€â”€ constants.py      # Game constants and maze layouts

</details>

ğŸ‘¥ Team Members:

Yi Yang

Chenle Wang

Kaiyue Yang
